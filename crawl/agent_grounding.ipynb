{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Agent with Tavily Search, Map, and Extract\n",
    "\n",
    "In this tutorial, you'll learn how to build a research agent that can crawl websites and reason over live web data.\n",
    "\n",
    "You will leverage the official [Tavily-LangChain integration](https://www.tavily.com/integrations/langchain) to autonomously set the crawl API parameters such as the crawl `instructions` or `catergories` based on the context and user instructions. \n",
    "\n",
    "By the end of this lesson, you'll know how to:\n",
    "- Seamlessly connect OpenAI foundation models to the web for up-to-date research\n",
    "- Build a react-style web agent with LangGraph\n",
    "- Dynamically configure search, extract, and crawl parameters with the Tavily-LangChain integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "\n",
    "1. **Sign up** for Tavily at [app.tavily.com](https://app.tavily.com/home/) to get your API key.\n",
    "\n",
    "\n",
    "2. **Sign up** for OpenAI to get your API key. Feel free to substitute any other LLM provider.\n",
    "   \n",
    "\n",
    "2. **Copy your API keys** from your Tavily and OpenAI account dashboard.\n",
    "\n",
    "3. **Paste your API keys** into the cell below and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API keys into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"TAVILY_API_KEY=<your-tavily-api-key>\" >> .env\n",
    "!echo \"OPENAI_API_KEY=<your-openai-api-key>\" >> .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U tavily-python langchain-openai langchain langchain-tavily langgraph --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Your Tavily API Client\n",
    "\n",
    "The code below will instantiate the Tavily client with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user to securely input the API key if not already set in the environment\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "# Initialize the Tavily API client using the loaded or provided API key\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the following modular tools with the Tavily-LangChain integration:\n",
    "1. **Search** the web for relevant information\n",
    "\n",
    "2. **Extract** content from specific web pages\n",
    "\n",
    "3. **Map** entire websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Map endpoint provides a sitemap of all links on a website, while crawling downloads the full content of each page. Sitemapping is more efficient when you just need the URL structure, as it avoids downloading and processing full page content. This makes it ideal for agents that need to understand site organization while staying within LLM context limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of web tools our agent will use to interact with the Tavily API.\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_tavily import TavilyExtract\n",
    "from langchain_tavily import TavilyMap\n",
    "\n",
    "# Define the LangChain search tool\n",
    "search = TavilySearch(max_results=10, topic=\"general\")\n",
    "\n",
    "# Define the LangChain extract tool\n",
    "extract = TavilyExtract(extract_depth=\"advanced\", format=\"markdown\")\n",
    "\n",
    "# Define the LangChain map tool\n",
    "map = TavilyMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up the gpt-4.1 model to power our agent. If you prefer a different LLM provider, you can easily plug in any LangChain Chat Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# instantiate the model\n",
    "o3 = ChatOpenAI(model=\"o3-2025-04-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Agent Setup\n",
    "\n",
    "Next, we'll build a Web Agent powered by Tavily, which consists of three main components: the language model, a set of web tools, and a system prompt. The language model (gpt-4.1) serves as the agent's \"brain,\" while the web tools (Search, Extract, and Crawl) allow the agent to interact with and gather information from the internet. The system prompt guides the agent's behavior, explaining how and when to use each tool to accomplish its research goals.\n",
    "\n",
    "You are encouraged to experiment with the system prompt or try different language models (like swapping between gpt-4.1 and o3) to change the agent's style, personality, or optimize its performance for specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.datetime.today().strftime(\"%A, %B %d, %Y\")\n",
    "PROMPT = f\"\"\"    \n",
    "        You are a research assistant created by the company Tavily. \n",
    "        Your mission is to conduct comprehensive, thorough, accurate, and up-to-date research, grounding your findings in credible web data.\n",
    "        \n",
    "        Today's Date: {today}\n",
    "\n",
    "        Guidelines:\n",
    "        - Your responses must be formatted nicely in markdown format. \n",
    "        - You must always provide web source citations for every claim you make.\n",
    "        - Ask follow up questions to the user before using the tools to ensure you have all the information you need to complete the task effectively.\n",
    "        - Do not ask clarifying questions to the user, just use the tools as needed.\n",
    "\n",
    "       You have access to the following tools: Web Search, Web Map, and Web Extract.\n",
    "\n",
    "        Tavily Web Search\n",
    "        - Retrieve relevant web pages from the public internet based on a search query.\n",
    "        - Provide a search query to receive semantically ranked results, each containing the title, URL, and a content snippet.\n",
    "\n",
    "        Tavily Web Map\n",
    "        - Explore a website's structure by generating a sitemap.\n",
    "        - Given a starting URL, find all the nested links.\n",
    "        - Useful for deep information discovery from a single source.\n",
    "        - You must be certain that the input URL is a valid URL.\n",
    "        - The URLs returned by the Map tool can later be scraped with the Extract tool.\n",
    "\n",
    "        Tavily Web Extract\n",
    "        - Extract/Scrape the full content from specific web pages, given a URL or a list of URLs.\n",
    "        - You can extract the full content of up to 20 URLs for efficient processing. Use this feature to enhance efficiency.\n",
    "\n",
    "        Use the following format:\n",
    "\n",
    "        Question: the input question you must answer\n",
    "        Thought: you should always think about what to do\n",
    "        Action: the action to take, should be one of Web Search, Web Crawl, and Web Extract\n",
    "        Action Input: the input to the action\n",
    "        Observation: the result of the action\n",
    "        ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "        Thought: I now know the final answer\n",
    "        Final Answer: the final answer to the original input question\n",
    "\n",
    "        ---\n",
    "\n",
    "        You will now receive a message from the user:\n",
    "\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent leverages a pre-built LangGraph reAct implementation, as illustrated in the diagram below. The reAct framework enables the agent to reason about which actions to take, use the web tools in sequence, and iterate as needed until it completes its research task. The system prompt is especially importantâ€”it instructs the agent on best practices for using the tools together, ensuring that the agent's responses are thorough, accurate, and well-sourced.\n",
    "\n",
    "<img src=\"../assets/crawl/web-agent.svg\" alt=\"Agent\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the web agent\n",
    "web_agent = create_react_agent(model=o3, tools=[search, map, extract], prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Tavily Web Agent\n",
    "\n",
    "Now we'll run the agent and see how it uses the different web tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Test the web agent\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"find all of the latest Tavily blog posts\")]\n",
    "}\n",
    "\n",
    "# Stream the web agent's response\n",
    "for s in web_agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the agent's intermediate steps printed above, including how it chooses and configures different tool parameters. Then, display the agent's final answer in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the agent cleverly combines Tavilyâ€™s toolsâ€”search, crawl, and extractâ€”to complete the task end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " \n",
    "In this tutorial, you learned how to:\n",
    "- Set up Tavily web tools (search, extract, crawl) with LangChain\n",
    "- Build an intelligent web research agent using LangGraph's `create_react_agent`\n",
    "- Design effective system prompts for autonomous web research\n",
    " \n",
    "You now have a fully functional web research agent that autonomously combines search, extraction, and crawling to complete complex research objectives.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
